{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import create_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(create_directory.recognition_model_dir, 'label2idx.json')) as json_file:\n",
    "    label2idx = json.load(json_file)\n",
    "\n",
    "def create_label_feature(feature_path, label2idx, ignore_unknown):\n",
    "    label_idx = []\n",
    "    feature = []\n",
    "    label_feat_dict = {}\n",
    "    for i in os.listdir(feature_path):\n",
    "        if i == \".DS_Store\":\n",
    "            continue\n",
    "        # Ta bỏ qua tất cả các data có nhãn Unknown\n",
    "        if ignore_unknown==True:\n",
    "            if i == \"Unknown\":\n",
    "                continue\n",
    "        label_feat_dict[i] = []\n",
    "        for j in os.listdir(os.path.join(feature_path, i)):\n",
    "            if j == \".DS_Store\":\n",
    "                continue\n",
    "            feat=np.load(os.path.join(os.path.join(feature_path, i), j))\n",
    "            feature.append(feat.reshape(128).tolist())\n",
    "            label_feat_dict[i].append(feat.reshape(128).tolist()) \n",
    "            label_idx.append(label2idx[i])\n",
    "    return label_idx, feature, label_feat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_path = os.path.join(create_directory.marvel_data_dir, \"feature/Train/hog_openface\")\n",
    "train_label_idx, train_feature, train_label_feat_dict = create_label_feature(train_feature_path, label2idx, ignore_unknown=True)\n",
    "test_feature_path = os.path.join(create_directory.marvel_data_dir, \"feature/Test/hog_openface\")\n",
    "test_label_idx, test_feature, test_label_feat_dict = create_label_feature(test_feature_path, label2idx, ignore_unknown=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lưu cơ sở dữ liệu cho quá trình nhận diện trong face_recognition.py\n",
    "data_path = os.path.join(create_directory.marvel_data_dir, \"distance_face_recognition/fixed_threshold\")\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path)\n",
    "with open(os.path.join(data_path, \"fixed_database.json\"), \"w\") as outfile:\n",
    "    json.dump(train_label_feat_dict, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phân chia dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixed Threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Big dataset: sử dụng cả dữ liệu train và dữ liệu test \n",
    "# (dữ liệu train làm tập cơ sở, dữ liệu test làm tập thử nghiệm)\n",
    "x_train_big = train_feature\n",
    "x_test_big = test_feature\n",
    "y_train_big = train_label_idx\n",
    "y_test_big = test_label_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_path, \"train_feature_big.json\"), \"w\") as outfile:\n",
    "    json.dump(x_train_big, outfile)\n",
    "with open(os.path.join(data_path, \"test_feature_big.json\"), \"w\") as outfile:\n",
    "    json.dump(x_test_big, outfile)\n",
    "with open(os.path.join(data_path, \"train_label_idx_big.json\"), \"w\") as outfile:\n",
    "    json.dump(y_train_big, outfile)\n",
    "with open(os.path.join(data_path, \"test_label_idx_big.json\"), \"w\") as outfile:\n",
    "    json.dump(y_test_big, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small dataset: chỉ sử dụng dữ liệu train\n",
    "# (dữ liệu train được chia ra làm 2 tập nhỏ hơn)\n",
    "x_train_small, x_test_small, y_train_small, y_test_small = train_test_split(train_feature, train_label_idx, test_size=0.33,\n",
    "                                                    random_state=4, stratify=train_label_idx)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ta lấy ngẫu nhiên 1/3 dữ liệu trong nhãn unknown\n",
    "unknown_feature_path = os.path.join(create_directory.marvel_data_dir, \"feature/Train/hog_openface/Unknown\")\n",
    "unknown_label_idx = []\n",
    "unknown_feature = []\n",
    "for j in os.listdir(unknown_feature_path):\n",
    "    if random.random()>0.33:\n",
    "        continue\n",
    "    if j == \".DS_Store\":\n",
    "        continue\n",
    "    feat=np.load(os.path.join(unknown_feature_path, j))\n",
    "    unknown_feature.append(feat.reshape(128).tolist())\n",
    "    unknown_label_idx.append(label2idx[\"Unknown\"])\n",
    "x_test_small+=unknown_feature\n",
    "y_test_small+=unknown_label_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_path, \"train_feature_small.json\"), \"w\") as outfile:\n",
    "    json.dump(x_train_small, outfile)\n",
    "with open(os.path.join(data_path, \"test_feature_small.json\"), \"w\") as outfile:\n",
    "    json.dump(x_test_small, outfile)\n",
    "with open(os.path.join(data_path, \"train_label_idx_small.json\"), \"w\") as outfile:\n",
    "    json.dump(y_train_small, outfile)\n",
    "with open(os.path.join(data_path, \"test_label_idx_small.json\"), \"w\") as outfile:\n",
    "    json.dump(y_test_small, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>label</th>\n",
       "      <th>threshold</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.02072661928832531, 0.124546118080616, -0.1...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.01946512795984745, 0.13560181856155396, -0...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.05963575094938278, 0.09309344738721848, 0....</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.11037980765104294, 0.023455195128917694, -0...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-0.002607713919132948, 0.12767337262630463, -...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature  label  threshold  idx\n",
       "0  [-0.02072661928832531, 0.124546118080616, -0.1...      3          2    0\n",
       "1  [-0.01946512795984745, 0.13560181856155396, -0...      3          2    1\n",
       "2  [-0.05963575094938278, 0.09309344738721848, 0....      3          2    2\n",
       "3  [0.11037980765104294, 0.023455195128917694, -0...      3          2    3\n",
       "4  [-0.002607713919132948, 0.12767337262630463, -...      3          2    4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'feature': train_feature, 'label': train_label_idx, 'threshold': [2]*len(train_label_idx)} \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "df[\"idx\"] = df.index\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(create_directory.marvel_data_dir, \"distance_face_recognition/adaptive_threshold\")\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path)\n",
    "df.to_csv(os.path.join(data_path, 'feature_euclidean.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['threshold'] = [0]*len(df)\n",
    "df.to_csv(os.path.join(data_path, 'feature_cosine.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_data_path = os.path.join(data_path, 'order')\n",
    "if not os.path.exists(order_data_path):\n",
    "    os.makedirs(order_data_path)\n",
    "order = np.arange(len(df)).tolist()\n",
    "register_order_num = 5\n",
    "for i in range(register_order_num):\n",
    "    random.shuffle(order)\n",
    "    with open(os.path.join(order_data_path, \"register_order_{}.json\".format(i)), \"w\") as outfile:\n",
    "        json.dump(order, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "edfc85cd6125fba325e43936d2e325e30e1e9112067751a66c5c52e50407c2e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
