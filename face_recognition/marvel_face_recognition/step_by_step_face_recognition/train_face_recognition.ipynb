{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import create_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tạo Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo label2idx\n",
    "label2idx = {'Chris Evans':0, 'Chris Hemsworth':1, 'Mark Ruffalo':2, 'Robert Downey Jr':3, \n",
    "             'Scarlett Johansson':4, 'Tom Holland':5, 'Unknown':6}\n",
    "with open(os.path.join(create_directory.recognition_model_dir, \"label2idx.json\"), \"w\") as outfile:\n",
    "    json.dump(label2idx, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(feature_path, label2idx, feature_extraction_type):\n",
    "    list_feature = []\n",
    "    list_label_idx = []\n",
    "    if feature_extraction_type==\"openface\":\n",
    "        path = os.path.join(feature_path, 'hog_openface')\n",
    "        size = 128\n",
    "    elif feature_extraction_type==\"facenet\":\n",
    "        path = os.path.join(feature_path, 'mtcnn_facenet')\n",
    "        size = 512\n",
    "    for i in os.listdir(path):\n",
    "        if i==\".DS_Store\":\n",
    "            continue\n",
    "        for j in os.listdir(os.path.join(path, i)):\n",
    "            if j==\".DS_Store\":\n",
    "                continue\n",
    "            list_label_idx.append(label2idx[i])\n",
    "            feature=np.load(os.path.join(os.path.join(path, i), j))\n",
    "            list_feature.append(feature.reshape(size).tolist())\n",
    "    return list_label_idx, list_feature\n",
    "\n",
    "feature_path = os.path.join(create_directory.marvel_data_dir, \"feature\")\n",
    "hog_label, hog_feature = get_feature(feature_path, label2idx, feature_extraction_type='openface')\n",
    "mtcnn_label, mtcnn_feature = get_feature(feature_path, label2idx, feature_extraction_type='facenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THỐNG KÊ DỮ LIỆU\n",
      " -hog_openface:\n",
      "{3: 228, 0: 164, 2: 174, 1: 156, 4: 197, 6: 187, 5: 186}\n",
      " -mtcnn_facenet:\n",
      "{3: 218, 0: 153, 2: 170, 1: 151, 4: 193, 6: 182, 5: 175}\n"
     ]
    }
   ],
   "source": [
    "# Thống kê dữ liệu\n",
    "def create_data_num(label):\n",
    "    data_num = {}\n",
    "    for i in label:\n",
    "        if i not in data_num:\n",
    "            data_num[i]=0\n",
    "        data_num[i]+=1\n",
    "    return data_num\n",
    "print(\"THỐNG KÊ DỮ LIỆU\")\n",
    "print(\" -hog_openface:\")\n",
    "print(create_data_num(hog_label))\n",
    "print(\" -mtcnn_facenet:\")\n",
    "print(create_data_num(mtcnn_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta sẽ lấy 1/3 ảnh ngẫu nhiên làm tập test, còn lại ta sẽ chia ra thành các mẫu để làm tập train, cụ thể:\n",
    "- Sample 1: sử dụng toàn bộ ảnh còn lại làm tập train\n",
    "- Sample 2: sử dụng 50% ảnh còn lại làm tập train\n",
    "- Sample 3: sử dụng 25% ảnh còn lại làm tập train\n",
    "- Sample 4: sử dụng 12.5% ảnh làm tập train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_data(feature, label):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(feature, label, test_size=0.33,\n",
    "                                                        random_state=4, stratify=label)\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "x_train_hog, x_test_hog, y_train_hog, y_test_hog = get_train_test_data(hog_feature, hog_label)\n",
    "x_train_mtcnn, x_test_mtcnn, y_train_mtcnn, y_test_mtcnn = get_train_test_data(mtcnn_feature, mtcnn_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample(feature, label, percentage, save_path, save_name):\n",
    "    data_num = create_data_num(label)\n",
    "    temp = list(zip(feature, label))\n",
    "    random.shuffle(temp)\n",
    "    feature, label = zip(*temp)\n",
    "    feature, label = list(feature), list(label)\n",
    "\n",
    "    count={}\n",
    "    sample_feature=[]\n",
    "    sample_label=[]\n",
    "    for feat, label in zip(feature, label):\n",
    "        if label not in count:\n",
    "            count[label]=0\n",
    "        if count[label]==int(data_num[label]*percentage):\n",
    "            continue\n",
    "        sample_feature.append(feat)\n",
    "        sample_label.append(label)\n",
    "        count[label]+=1\n",
    "    with open(os.path.join(save_path, save_name+\"_feature\"+\".json\"), \"w\") as outfile:\n",
    "        json.dump(sample_feature, outfile)\n",
    "    with open(os.path.join(save_path, save_name+\"_label_idx.json\"), \"w\") as outfile:\n",
    "        json.dump(sample_label, outfile)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(create_directory.marvel_data_dir, 'sample_feature')\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "save_path_hog = os.path.join(save_path, 'hog_openface')\n",
    "if not os.path.exists(save_path_hog):\n",
    "    os.makedirs(save_path_hog)\n",
    "save_path_mtcnn = os.path.join(save_path, 'mtcnn_facenet')\n",
    "if not os.path.exists(save_path_mtcnn):\n",
    "    os.makedirs(save_path_mtcnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lưu dữ liệu test\n",
    "with open(os.path.join(save_path_hog, \"test_feature.json\"), \"w\") as outfile:\n",
    "    json.dump(x_test_hog, outfile)\n",
    "with open(os.path.join(save_path_hog, \"test_label_idx.json\"), \"w\") as outfile:\n",
    "    json.dump(y_test_hog, outfile)\n",
    "with open(os.path.join(save_path_mtcnn, \"test_feature.json\"), \"w\") as outfile:\n",
    "    json.dump(x_test_mtcnn, outfile)\n",
    "with open(os.path.join(save_path_mtcnn, \"test_label_idx.json\"), \"w\") as outfile:\n",
    "    json.dump(y_test_mtcnn, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0: 12.5% train data\n",
      "    -hog openface\n",
      "    -mtcnn facenet\n",
      "Sample 1: 25.0% train data\n",
      "    -hog openface\n",
      "    -mtcnn facenet\n",
      "Sample 2: 50.0% train data\n",
      "    -hog openface\n",
      "    -mtcnn facenet\n",
      "Sample 3: 100% train data\n",
      "    -hog openface\n",
      "    -mtcnn facenet\n"
     ]
    }
   ],
   "source": [
    "sample_percentage = [0.125, 0.25, 0.5, 1]\n",
    "for idx, percentage in enumerate(sample_percentage):\n",
    "    print(\"Sample {}: {}% train data\".format(idx, percentage*100))\n",
    "    print('    -hog openface')\n",
    "    create_sample(x_train_hog, y_train_hog, percentage,\n",
    "                  save_path=save_path_hog, \n",
    "                  save_name='train_sample_{}'.format(idx))\n",
    "    print('    -mtcnn facenet')\n",
    "    create_sample(x_train_mtcnn, y_train_mtcnn, percentage,\n",
    "                  save_path=save_path_mtcnn, \n",
    "                  save_name='train_sample_{}'.format(idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model_hog_openface_path = os.path.join(create_directory.recognition_model_dir, \"hog_openface_svm_model.sav\")\n",
    "svm_model_mtcnn_facenet_path = os.path.join(create_directory.recognition_model_dir, \"mtcnn_facenet_svm_model.sav\")\n",
    "knn_model_hog_openface_path = os.path.join(create_directory.recognition_model_dir, \"hog_openface_knn_model.sav\")\n",
    "knn_model_mtcnn_facenet_path = os.path.join(create_directory.recognition_model_dir, \"mtcnn_facenet_knn_model.sav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xây dựng hàm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm huấn luyện mô hình\n",
    "def train_model(x_train, x_test, y_train, y_test, model_type, save, model_path=''):\n",
    "    if model_type == 'svm':\n",
    "        # Training SVM model\n",
    "        param_grid = {\n",
    "                'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "                'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1],\n",
    "                }\n",
    "        clf = GridSearchCV(svm.SVC(kernel='rbf', class_weight='balanced'), param_grid)\n",
    "    elif model_type == 'knn':\n",
    "        # Training KNN model\n",
    "        param_grid = {\n",
    "                'n_neighbors': [3, 5, 7]\n",
    "                }\n",
    "        clf = GridSearchCV(KNeighborsClassifier(weights='distance'), param_grid)\n",
    "    clf = clf.fit(x_train, y_train)\n",
    "    # print(\"Best estimator found by grid search:\")\n",
    "    # print(clf.best_estimator_)\n",
    "    if save == 1:\n",
    "        joblib.dump(clf, model_path)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    return y_test, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm đánh giá\n",
    "def evaluation(true, pred):\n",
    "    fa = 0  # False accept\n",
    "    wa = 0  # Wrong answer\n",
    "    fr = 0  # False reject\n",
    "    accept = 0\n",
    "    reject = 0\n",
    "    for (i, j) in zip(true, pred):\n",
    "        # Hệ thống nhận diện khuôn mặt đó có trong database\n",
    "        if j != label2idx[\"Unknown\"]:\n",
    "            accept+=1\n",
    "            # Hệ thống nhận diện khuôn mặt Unknown thành khuôn mặt trong database\n",
    "            if i == label2idx[\"Unknown\"]:\n",
    "                fa+=1\n",
    "            else:\n",
    "                # Hệ thống nhận diện nhầm khuôn mặt trong database\n",
    "                if i!=j:\n",
    "                    wa+=1\n",
    "        else:\n",
    "            reject+=1\n",
    "            if i != label2idx[\"Unknown\"]:\n",
    "                fr+=1\n",
    "    accuracy = accuracy_score(true, pred)\n",
    "    # Mong muốn giảm fa, wa\n",
    "    return (fa, wa, fr, accept, reject, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_list=[0, 1, 2, 3]\n",
    "def process(data_path, sample_list, model_type):\n",
    "    for i in sample_list:\n",
    "        print('Sample {}'.format(i))\n",
    "        with open(os.path.join(data_path, \"train_sample_{}_feature.json\".format(i)), \"r\") as outfile:\n",
    "            x_train = json.load(outfile)\n",
    "        with open(os.path.join(data_path, \"test_feature.json\"), \"r\") as outfile:\n",
    "            x_test = json.load(outfile)\n",
    "        with open(os.path.join(data_path, \"train_sample_{}_label_idx.json\".format(i)), \"r\") as outfile:\n",
    "            y_train = json.load(outfile)\n",
    "        with open(os.path.join(data_path, \"test_label_idx.json\"), \"r\") as outfile:\n",
    "            y_test = json.load(outfile)\n",
    "        y_test, y_pred = train_model(x_train, x_test, y_train, y_test, model_type, save=0)\n",
    "        fa, wa, fr, accept, reject, accuracy = evaluation(y_test, y_pred)\n",
    "        print(' - Accept: {}, False Accept: {}, Wrong Answer: {}'.format(accept, fa, wa))\n",
    "        print(' - Reject: {}, False Reject: {}'.format(reject, fr))\n",
    "        print(' - Accuracy: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOG + Openface "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(create_directory.marvel_data_dir, 'sample_feature/hog_openface')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0\n",
      " - Accept: 384, False Accept: 29, Wrong Answer: 21\n",
      " - Reject: 43, False Reject: 10\n",
      " - Accuracy: 0.8594847775175644\n",
      "Sample 1\n",
      " - Accept: 377, False Accept: 28, Wrong Answer: 16\n",
      " - Reject: 50, False Reject: 16\n",
      " - Accuracy: 0.8594847775175644\n",
      "Sample 2\n",
      " - Accept: 365, False Accept: 18, Wrong Answer: 12\n",
      " - Reject: 62, False Reject: 18\n",
      " - Accuracy: 0.8875878220140515\n",
      "Sample 3\n",
      " - Accept: 366, False Accept: 17, Wrong Answer: 17\n",
      " - Reject: 61, False Reject: 16\n",
      " - Accuracy: 0.882903981264637\n"
     ]
    }
   ],
   "source": [
    "process(data_path, sample_list, model_type='svm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0\n",
      " - Accept: 413, False Accept: 52, Wrong Answer: 29\n",
      " - Reject: 14, False Reject: 4\n",
      " - Accuracy: 0.8009367681498829\n",
      "Sample 1\n",
      " - Accept: 398, False Accept: 40, Wrong Answer: 27\n",
      " - Reject: 29, False Reject: 7\n",
      " - Accuracy: 0.8266978922716628\n",
      "Sample 2\n",
      " - Accept: 385, False Accept: 28, Wrong Answer: 20\n",
      " - Reject: 42, False Reject: 8\n",
      " - Accuracy: 0.8688524590163934\n",
      "Sample 3\n",
      " - Accept: 380, False Accept: 22, Wrong Answer: 19\n",
      " - Reject: 47, False Reject: 7\n",
      " - Accuracy: 0.8875878220140515\n"
     ]
    }
   ],
   "source": [
    "process(data_path, sample_list, model_type='knn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MTCNN + Facenet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(create_directory.marvel_data_dir, 'sample_feature/mtcnn_facenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0\n",
      " - Accept: 355, False Accept: 8, Wrong Answer: 1\n",
      " - Reject: 55, False Reject: 3\n",
      " - Accuracy: 0.9707317073170731\n",
      "Sample 1\n",
      " - Accept: 359, False Accept: 10, Wrong Answer: 1\n",
      " - Reject: 51, False Reject: 1\n",
      " - Accuracy: 0.9707317073170731\n",
      "Sample 2\n",
      " - Accept: 357, False Accept: 8, Wrong Answer: 3\n",
      " - Reject: 53, False Reject: 1\n",
      " - Accuracy: 0.9707317073170731\n",
      "Sample 3\n",
      " - Accept: 350, False Accept: 1, Wrong Answer: 3\n",
      " - Reject: 60, False Reject: 1\n",
      " - Accuracy: 0.9878048780487805\n"
     ]
    }
   ],
   "source": [
    "process(data_path, sample_list, model_type='svm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0\n",
      " - Accept: 388, False Accept: 38, Wrong Answer: 1\n",
      " - Reject: 22, False Reject: 0\n",
      " - Accuracy: 0.9048780487804878\n",
      "Sample 1\n",
      " - Accept: 376, False Accept: 26, Wrong Answer: 1\n",
      " - Reject: 34, False Reject: 0\n",
      " - Accuracy: 0.9341463414634147\n",
      "Sample 2\n",
      " - Accept: 370, False Accept: 20, Wrong Answer: 0\n",
      " - Reject: 40, False Reject: 0\n",
      " - Accuracy: 0.9512195121951219\n",
      "Sample 3\n",
      " - Accept: 356, False Accept: 6, Wrong Answer: 0\n",
      " - Reject: 54, False Reject: 0\n",
      " - Accuracy: 0.9853658536585366\n"
     ]
    }
   ],
   "source": [
    "process(data_path, sample_list, model_type='knn')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "edfc85cd6125fba325e43936d2e325e30e1e9112067751a66c5c52e50407c2e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
